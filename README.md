
# PARADOX: Pharmacological Analysis of Relation Anomalies and Drug Contradictions Extraction

This repository contains the official research implementation of **PARADOX**, a framework for detecting, validating, and graphically modeling **pharmacological contradictions** in drugâ€“drug relations extracted from biomedical literature.

PARADOX is designed as a **contradiction-aware enrichment layer** over an existing drug relation ontology, enabling more reliable and interpretable biomedical knowledge graphs.



## ğŸ“Œ Overview

Automatic extraction of drugâ€“drug relations from biomedical text often produces large but noisy relational graphs, where **logical inconsistencies and semantic contradictions** are inevitable. Such contradictions can mislead downstream reasoning, inference, and decision-support systems.

**PARADOX** addresses this problem by introducing a structured pipeline that:

* Identifies candidate contradictory drug relations,
* Expands contradiction hypotheses through semantic similarity (snowball strategy),
* Validates contradictions using **large language models (LLMs)**,
* Constructs a **contradiction-aware knowledge graph** based only on verified evidence.

The framework is evaluated on **PubMed abstracts (2022â€“2024)** and demonstrates high recall in contradiction detection while maintaining controlled graph complexity.



## ğŸ§  Methodology

The PARADOX framework consists of five main stages:

1. **Concept Grouping**
   Semantically similar drug concepts are grouped to reduce redundancy and stabilize candidate generation.

2. **Biomedical Sentence Mining**
   Sentences mentioning candidate drug pairs are extracted from PubMed abstracts.

3. **Iterative Contradiction Discovery**
   A multi-step snowball expansion strategy is applied to identify contradiction candidates based on semantic similarity thresholds.

4. **LLM-based Validation**
   Candidate contradictions are evaluated using GPT-based models to remove weak or spurious inconsistencies.

5. **Contradiction Graph Construction**
   Only validated contradictions are represented as edges in the final contradiction graph.



## ğŸ“Š Experimental Summary

* **Corpus**: PubMed abstracts (2022â€“2024)
* **Extracted relational statements**: >18,000
* **Detected contradiction candidates**: 42
* **Validated contradictions**: 39
* **Recall (Contradiction class)**: **92.86%**
* **Final output**: LLM-validated contradiction graph

The pipeline adopts a **recall-oriented detection strategy**, ensuring that critical contradictions are not missed, while downstream validation controls false positives.



## ğŸ”— Relation to DREaM

PARADOX operates on top of the ontology produced by **DREaM (Drugâ€“Drug Relation Extraction via Transfer Learning)**.
While DREaM focuses on extracting and structuring drugâ€“drug relations, PARADOX refines this structure by identifying inconsistencies, contradictions, and latent relational anomalies.



## ğŸ“ Repository Structure

```
PARADOX/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ PubMed_abstracts.csv
â”‚   â”œâ”€â”€ DREaM_drug_relations.csv
â”‚   â”œâ”€â”€ Candidate_sentence_pairs.csv
â”‚   â”œâ”€â”€ Gs_similarity_edges.csv
â”‚   â””â”€â”€ Labeled_data_by_LLM.csv
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ siamese_model_training.ipynb
â”‚   â”œâ”€â”€ contradiction_candidate_expansion.ipynb
â”‚   â””â”€â”€ paradox_pipeline.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ Confusion-matrix.png
â”‚   â”œâ”€â”€ Contradiction-graph.png
â”‚   â”œâ”€â”€ Contradictory-concepts.csv
â”‚   â”œâ”€â”€ Results-per-snowball.png
â”‚   â””â”€â”€ Results-per-snowball-percentage.png
â”‚
â””â”€â”€ README.md
```

### ğŸ“‚ Folder Description

* **data/**
  Contains input resources:
  * `PubMed_abstracts.csv`: Biomedical abstracts from PubMed (2022â€“2024)
  * `DREaM_drug_relations.csv`: The drug relation ontology generated by DREaM
  * `Candidate_sentence_pairs.csv`: Extracted sentence pairs for contradiction analysis
  * `Gs_similarity_edges.csv`: Semantic similarity edges for concept grouping
  * `Labeled_data_by_LLM.csv`: LLM-validated contradiction labels

* **code/**
  Contains Jupyter notebooks implementing the PARADOX pipeline.
  Each notebook corresponds to a conceptual stage of the framework and can be executed independently.

* **results/**
  Stores evaluation outputs:
  * `Confusion-matrix.png`: Classification performance metrics
  * `Contradiction-graph.png`: Visual representation of the contradiction graph
  * `Contradictory-concepts.csv`: Validated contradictory concept pairs
  * `Results-per-snowball.png`: Snowball expansion analysis results
  * `Results-per-snowball-percentage.png`: Percentage-based snowball analysis



## â–¶ï¸ How to Run the Code

All experiments are implemented as **Jupyter Notebooks**.
There is no centralized execution script; notebooks are designed for **cell-by-cell reproducibility**.

Recommended execution order:

1. **Train and apply the Siamese similarity model**

   ```
   code/siamese_model_training.ipynb
   ```

2. **Run iterative contradiction candidate expansion**

   ```
   code/contradiction_candidate_expansion.ipynb
   ```

3. **Validate contradictions and construct the graph**

   ```
   code/paradox_pipeline.ipynb
   ```

Each notebook includes explanatory comments and intermediate outputs to support transparency and reproducibility.



## âš™ï¸ Requirements

The implementation relies on standard Python libraries for NLP and deep learning, including:

* Python â‰¥ 3.8
* PyTorch
* Transformers
* NumPy / Pandas
* Scikit-learn
* Jupyter Notebook

(An explicit `requirements.txt` can be added if needed.)


## âš ï¸ Disclaimer

This repository is intended **for research purposes only**.
The extracted relations and detected contradictions should not be used directly for clinical decision-making.



## ğŸ¤ Acknowledgments

This work builds upon research in:

* Biomedical relation extraction,
* Knowledge graph construction,
* Contradiction detection,
* Large language models.
